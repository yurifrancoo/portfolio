# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xxv1ZtQVRhsO-_KhxK3FD20giPuBY85j
"""

# Importar Bibliotecas
import os
import pyodbc

dados = []
for arquivos in os.listdir(caminho_pasta): # Listar o nome dos arquivos csv
    caminho = os.path.join(caminho_pasta,arquivos)
    with open(caminho, 'r') as dados_arquivos: # Abrir cada arquivo csv
        linhas = dados_arquivos.readlines()[1:] # Desconsiderar o cabecalho de cada arquivo csv
        for linha in linhas:
            linhas = [linha.rstrip()] # Remover a quebra de linha '\n' linha por linha
            dados.extend(linhas) # Adicionar as linhas na lista vazia 'dados'

# Detalhes da conexão
server = 'localhost\\SQLEXPRESS'
database = 'trabalho_final_ibge'
username = 'LAPTOP-9EAIMND6\\yurif'

# Construir a string de conexão
conn_str = f'DRIVER={{SQL Server}};SERVER={server};DATABASE={database};UID={username};Trusted_Connection=yes'

# Conectar ao banco de dados
conn = pyodbc.connect(conn_str)

# Cursor para executar comandos SQL
cursor = conn.cursor()

# Inserir valores na tabela "tabela_ibge" já existente no banco de dados SQL Server
sql = """
    INSERT INTO tabela_ibge
    (COD_UF, COD_MUN, COD_ESPECIE, LATITUDE, LONGITUDE, NV_GEO_COORD)
    VALUES (?, ?, ?, ?, ?, ?)
"""

# Iterar sobre os dados e inseri-los na tabela
for linha in dados:
    valores = linha.split(';')
    cursor.execute(sql, valores)

# Commit para salvar as alterações
conn.commit()

# Fechar a conexão
conn.close()

print('Dados carregados com sucesso')

# 4.Pontos de dificuldade, quais pontos a favor da técnica usada e soluções de mercado.
# Tive dificuldade em todas as etapas, visto que nunca utilizei essas bibliotecas. Então tive que pesquisar sobre quais bibliotecas e funções atenderiam a lógica que eu tinha montado e também atender o volume de dados proposto. Tive dificuldade em perceber a diferença do .readline() e readlines(), em como remover a quebra de linha da lista criada e dificuldades em declarar os tipos de cada coluna no banco de dados SQL Server, pois primeiramente eu tinha criado uma tabela com colunas varchar, em vez de int e float.
# O grande ponto a favor foi em relação a biblioteca pyodbc que conecta diretamente com o banco de dados, sem precisar colocar a tabela unificada na máquina local e somente após isso levar para um banco de dados. Outro ponto positivo foi com a biblioteca OS que pega todos os arquivos da pasta direcionada (por meio do os.listdir), sem precisar nomear um por um, o que facilitou bastante na construção do código.
# Com certeza permitir o uso das bibliotecas pandas e spark ajudaria no processo de levar todas essas linhas para o banco de dados, principalmente o spark pelo seu processamento otimizado para grande volume de dados